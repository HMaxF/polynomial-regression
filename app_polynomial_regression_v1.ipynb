{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a82066-840a-4c52-8ef8-141c412c974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Application to build Machine Learning model based on input data.\n",
    "\n",
    "App v0.99\n",
    "\n",
    "Hariyanto Lim\n",
    "\"\"\"\n",
    "import sys # to get arguments (parameter) manually\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from sklearn.metrics import mean_squared_error # == [(a - b) ** 2]\n",
    "from sklearn.metrics import mean_absolute_error # == [abs(a - b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38f71735-2c14-48fb-bec6-18eae239a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, poly, filename):\n",
    "    print('### save_model()')\n",
    "\n",
    "    # save the model and the poly to disk\n",
    "    pickle.dump((model, poly), open(filename, 'wb'))\n",
    "\n",
    "def load_model(filename):\n",
    "\n",
    "    try:\n",
    "        # load both model and poly\n",
    "        model, poly = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "        print(f\"### load_model(): '{filename}' loaded\")\n",
    "\n",
    "        return model, poly\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"### load_model(): error '{filename}' not found\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def evaluate_model(modelLR, poly, X, y):\n",
    "\n",
    "    if poly is None:\n",
    "        # using Linear\n",
    "\n",
    "        # predict\n",
    "        y_pred = modelLR.predict(X)\n",
    "    else:\n",
    "        # using poly\n",
    "                \n",
    "        # transform X_train value to poly to make it in the same form\n",
    "        X_poly = poly.transform(X)\n",
    "\n",
    "        # predict\n",
    "        y_pred = modelLR.predict(X_poly)\n",
    "\n",
    "    \"\"\"\n",
    "    LEARNING POINT: after predict then check the accuracy\n",
    "    \"\"\"    \n",
    "    # 1st check using R2 score\n",
    "    a_r2_score = r2_score(y, y_pred)\n",
    "    \n",
    "    # 2nd check using MAE (Mean Absolute Error)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    \n",
    "    #print(f\"\\n### accuracy check\")\n",
    "    print(f\"R2 score = {a_r2_score:.7f}, [closer to 1.0 is better]\")\n",
    "    print(f\"MeanAbsoluteError = {mae:,.1f}, [close to 0.0 is better]\")\n",
    "    #print(f\"###\\n\")\n",
    "\n",
    "    \"\"\"\n",
    "    LEARNING POINT: to improve accuracy, we can search and remove outliers.\n",
    "\n",
    "    NOTE: \n",
    "    1. Removing outliers is optional.\n",
    "    2. IF we want to search for outlier in a dataset, we can use Interquartile Range (IQR)\n",
    "       but if we want to search for outlier after prediction then this is 1 of the many ways.\n",
    "    \"\"\"\n",
    "    find_outliers_after_prediction = True \n",
    "    if find_outliers_after_prediction:\n",
    "        # change to 1D and convert to int\n",
    "        y_pred = y_pred.flatten().astype(int) \n",
    "\n",
    "        # Use 'Threshold' as limit to compare and find outliers.\n",
    "        # What 'Threshold' value is suitable? that is depend on our data!!\n",
    "        threshold = 1000\n",
    "        temp = find_outlier_as_table(y.flatten(), y_pred, threshold) # flatten y to 1D array\n",
    "\n",
    "        print(f\"===== Outliers table =====\")\n",
    "        #pd.set_option('display.max_rows', None)  # Set max_rows to None to display all rows  \n",
    "        print(temp) # display to check visually\n",
    "\n",
    "        \"\"\"\n",
    "        After outliers are found, analyze whether to keep or remove outliers,\n",
    "        1. Sometimes outliers are useful in continuous regression.\n",
    "        2. Analyze if one or more features may not have strong **Correlation**,\n",
    "            so need to check and remove the feature then re-build model.\n",
    "            eg: in house price prediction, the total doors and total windows\n",
    "                may not have strong correlation therefore these features can be removed.\n",
    "        \"\"\"\n",
    "\n",
    "    ############ end of optional #####################################\n",
    "\n",
    "    return\n",
    "\n",
    "def find_outlier_as_table(target, predicted, threshold):\n",
    "    \"\"\"\n",
    "    Outlier is data point that stands out from the rest of the group.\n",
    "    It's either much higher or lower than most of the other data points in the set.\n",
    "\n",
    "    Create a DataFrame containing target, predicted, MAE, and outlier flag.\n",
    "    Parameters:\n",
    "    target (list or array-like): The array of actual values.\n",
    "    predicted (list or array-like): The array of predicted values.\n",
    "    threshold (float): The threshold value for detecting outliers.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing target, predicted, MAE, and outlier flag.\n",
    "    \"\"\"\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = [abs(t - p) for t, p in zip(target, predicted)]\n",
    "    \n",
    "    # Determine outliers\n",
    "    outliers = [1 if error > threshold else 0 for error in mae]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'target': target,\n",
    "        'predicted': predicted,\n",
    "        'mae': mae,\n",
    "        'outlier': outliers\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# function to build optimal model\n",
    "def create_model(df, use_polynomial):\n",
    "    \"\"\"\n",
    "    Main job: create model from DataFrame    \n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"### create_model(DataFrame, {use_polynomial=})\")\n",
    "\n",
    "    # define X ==> data to train (independent) and y ==> the target (dependent, annotated)\n",
    "    X = df.drop(df.columns[-1], axis=1) # df.columns[-1] == the most right side column\n",
    "    y = df.take([-1], axis=1)\n",
    "\n",
    "    \"\"\"\n",
    "    Optional check: data to learn (X) should be numerical (int or float), there should NOT be any blank, text, or symbol.    \n",
    "    \"\"\"\n",
    "    numeric_df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    is_all_numeric = not numeric_df.isnull().values.any()\n",
    "    if is_all_numeric == False:\n",
    "        print(f\"*** ERROR: the data content of CSV to be used as training model has non-numeric value, please fix this!\")\n",
    "        print(df)\n",
    "        return None\n",
    "    \n",
    "    \"\"\"\n",
    "    LEARNING POINT: A common exercise to split the input data for training and for testing,\n",
    "    Reasons:\n",
    "    1. To evaluate the model we should not use data from other source,\n",
    "       we only trust all data points from this same source.\n",
    "    2. To create unseen data to get performance of the model using unseen data later.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # create the model variable, \n",
    "    # NOTE: in scikit, Polynomial Regression also using LinearRegression\n",
    "    modelLR = LinearRegression()\n",
    "\n",
    "    if use_polynomial:\n",
    "        # Polynomial regression need 'degree' parameter, so create it\n",
    "        degree, poly = create_optimal_polynomial_degree(modelLR, X_train.values, y_train.values)\n",
    "\n",
    "        #print(f\"Polynomial Regression model is created with degree = {degree}\")\n",
    "    else:\n",
    "        # using Linear Regression\n",
    "        # with only values (exclude header text)\n",
    "        modelLR.fit(X_train.values, y_train.values)\n",
    "        poly = None # indicate it is Linear Regression\n",
    "\n",
    "        print(f\"Linear Regression model is created\")\n",
    "\n",
    "    # show the coefficient and intercept value\n",
    "    print(f\"***\\nCoefficients = {modelLR.coef_}\\nIntercept = {modelLR.intercept_}\\n***\")\n",
    "\n",
    "    \"\"\"\n",
    "    LEARNING POINT: After model is created, it is time to use the model to predict the same trained data\n",
    "    Reasons:\n",
    "    1. Model assessment, predicting on the training data allows us\n",
    "       to assess how well the model fits the training data.\n",
    "    2. Debugging and understanding, Examining the predictions on the training data\n",
    "       can help in debugging the model and understanding its behavior.\n",
    "       By comparing the predicted values with the actual values in the training set,\n",
    "       we can identify potential issues such as underfitting, overfitting, or data preprocessing errors.\n",
    "       IF we found problem THEN we can try to update the model\n",
    "    \"\"\"\n",
    "    print(f\"\\n***** Evaluate model using TRAINED data *****\")\n",
    "    evaluate_model(modelLR, poly, X_train.values, y_train.values)\n",
    "    print(f\"***** end of evaluation using trained data *****\")\n",
    "\n",
    "    \"\"\"\n",
    "    LEARNING POINT: After model assessment is done and the performance is accepted,\n",
    "    then predict the unseen testing data.\n",
    "    Reasons:\n",
    "    1. Model evaluation, create unseen data to get performance of the model using unseen data later.\n",
    "    2. Prevent overfitting, to check if the model is effective only on trained data but not on unseen data.    \n",
    "    \"\"\"\n",
    "    print(f\"\\n***** Evaluate model using UNSEEN TESTING data *****\")\n",
    "    evaluate_model(modelLR, poly, X_test.values, y_test.values)\n",
    "    print(f\"***** end of evaluation using unseen testing data *****\")\n",
    "\n",
    "    \"\"\"\n",
    "    LEARNING POINT: Comparing the result of trained data and unseen data,\n",
    "    if they are close then the model is good.\n",
    "    if they are not close then maybe the model is overfit to the trained data\n",
    "        and if the model is overfit then reduce the 'degree' value.\n",
    "    \"\"\"\n",
    "\n",
    "    return modelLR, poly\n",
    "\n",
    "def create_optimal_polynomial_degree(modelLR, X_train, y_train):\n",
    "    print(f\"Create optimal Polynomial degree\")\n",
    "\n",
    "    r2_score_lower_limit_threshold = 0.1\n",
    "    degree_highest_r2_score = 0\n",
    "    highest_r2_score = 0\n",
    "\n",
    "    degree = 2 # NOTE: minimum Polynomial degree is 2\n",
    "\n",
    "    a_r2_score = 0\n",
    "\n",
    "    \"\"\"\n",
    "    In my experience, higher degree (ie: > 4) normally overfit,    \n",
    "    the unseen data can not be predicted well.\n",
    "\n",
    "    So we set target of lower r2_score to prevent using higher degree.\n",
    "    \"\"\"\n",
    "    min_r2_score = 0.90 # if more than maybe overfit\n",
    "\n",
    "    y_poly_pred = None\n",
    "\n",
    "    # In this example, find optimal 'degree' ONLY up to 10\n",
    "    while degree <= 10 and a_r2_score < min_r2_score: \n",
    "        \"\"\"\n",
    "        WARNING: the higher the 'degree' value, the SLOWER the prediction !!!\n",
    "        \"\"\"\n",
    "        \n",
    "        poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "\n",
    "        # transform X_train value to poly        \n",
    "        X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "        # train the transformed (using PolynomialFeatures) data\n",
    "        modelLR.fit(X_train_poly, y_train)\n",
    "\n",
    "        # predict the training data to see r2_score\n",
    "        y_poly_pred = modelLR.predict(X_train_poly)\n",
    "        \n",
    "        # NOTE: in this demo, we only use r2_score() to check the accuracy\n",
    "        a_r2_score = r2_score(y_train, y_poly_pred)\n",
    "        if a_r2_score < min_r2_score:\n",
    "            print(f\"degree = {degree} only got r2 score = {a_r2_score}\")\n",
    "        \n",
    "        if a_r2_score > highest_r2_score:\n",
    "            # save it\n",
    "            highest_r2_score = a_r2_score\n",
    "            degree_highest_r2_score = degree\n",
    "        elif a_r2_score < highest_r2_score - r2_score_lower_limit_threshold:\n",
    "            \"\"\"\n",
    "            IF r2_score is smaller when using higher 'degree'\n",
    "            THEN it means accuracy went down\n",
    "            NORMALLY it won't go up again, so break loop\n",
    "            \"\"\" \n",
    "            print(f\"degree={degree}'s r2 score is lower than previously, so break loop\")\n",
    "            break\n",
    "\n",
    "        degree += 1 # increase trial counter\n",
    "\n",
    "    #################################################\n",
    "    # recreate the model and the poly using the degree_highest_r2_score \n",
    "    # because current model and poly may be different than HIGHEST R2 model & poly.\n",
    "\n",
    "    poly = PolynomialFeatures(degree=degree_highest_r2_score, include_bias=False)\n",
    "\n",
    "    # transform X_train value to poly        \n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "    # train the transformed (using PolynomialFeatures) data\n",
    "    modelLR.fit(X_train_poly, y_train)\n",
    "    #################################################\n",
    "    \n",
    "    print(f\"***\\nFound optimal Polynomial degree = {degree_highest_r2_score}\")\n",
    "    print(f\"Highest r2 score = {highest_r2_score}\\n***\")\n",
    "\n",
    "    return degree_highest_r2_score, poly\n",
    "\n",
    "def load_csv_into_dataframe(csv_filename):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_filename)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"*** load_csv_into_dataframe(): '{csv_filename}' not found\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7684dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Size (mÂ²)  Age (years)  Price\n",
      "0          30           10   4718\n",
      "1          31           10   5078\n",
      "2          32            4   6001\n",
      "3          33            7   6220\n",
      "4          33            8   6120\n",
      "..        ...          ...    ...\n",
      "95         97           10  54903\n",
      "96         98            9  56213\n",
      "97         99            2  57800\n",
      "98         99            4  57767\n",
      "99         99            9  57374\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#input_filename = \"house_price_30_all_numerical.csv\"\n",
    "input_filename = \"random_polynomial_house_prices.csv\"\n",
    "\n",
    "df = load_csv_into_dataframe(input_filename)\n",
    "if df is None:\n",
    "    print(f\"load csv '{input_filename}' failed\")\n",
    "    exit(-3)\n",
    "\n",
    "# display data to verify content\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ba38598-df4f-4447-a7fa-3186f6a66ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### create_model(DataFrame, use_polynomial=False)\n",
      "Linear Regression model is created\n",
      "***\n",
      "Coefficients = [[778 -115]]\n",
      "Intercept = [-22669]\n",
      "***\n",
      "\n",
      "***** Evaluate model using TRAINED data *****\n",
      "R2 score = 0.9807639, [closer to 1.0 is better]\n",
      "MeanAbsoluteError = 1,922.3, [close to 0.0 is better]\n",
      "===== Outliers table =====\n",
      "    target  predicted   mae  outlier\n",
      "0    13958      14625   667        0\n",
      "1    54227      51287  2940        1\n",
      "2     6813       3538  3275        1\n",
      "3    33938      35735  1797        1\n",
      "4    34028      35966  1938        1\n",
      "..     ...        ...   ...      ...\n",
      "62   29726      32308  2582        1\n",
      "63   37156      38385  1229        1\n",
      "64    9612       8289  1323        1\n",
      "65   52926      50279  2647        1\n",
      "66   24152      26865  2713        1\n",
      "\n",
      "[67 rows x 4 columns]\n",
      "***** end of evaluation using trained data *****\n",
      "\n",
      "***** Evaluate model using UNSEEN TESTING data *****\n",
      "R2 score = 0.9812154, [closer to 1.0 is better]\n",
      "MeanAbsoluteError = 1,827.3, [close to 0.0 is better]\n",
      "===== Outliers table =====\n",
      "    target  predicted   mae  outlier\n",
      "0    46679      46074   605        0\n",
      "1    24616      26951  2335        1\n",
      "2    36506      37838  1332        1\n",
      "3    21929      24417  2488        1\n",
      "4    21227      23755  2528        1\n",
      "5    16768      18283  1515        1\n",
      "6    12049      12062    13        0\n",
      "7    45371      44836   535        0\n",
      "8     7627       4978  2649        1\n",
      "9     4718       -493  5211        1\n",
      "10   10603       9845   758        0\n",
      "11   14706      15749  1043        1\n",
      "12   38658      39854  1196        1\n",
      "13   15038      16065  1027        1\n",
      "14   53212      50855  2357        1\n",
      "15    6120       2069  4051        1\n",
      "16   42182      42388   206        0\n",
      "17   43582      43741   159        0\n",
      "18    7441       4517  2924        1\n",
      "19   14617      15518   901        0\n",
      "20   26474      29313  2839        1\n",
      "21   51911      49616  2295        1\n",
      "22   13550      14193   643        0\n",
      "23   18860      20731  1871        1\n",
      "24   36734      38183  1449        1\n",
      "25    9484       8174  1310        1\n",
      "26   18490      20644  2154        1\n",
      "27   56213      52496  3717        1\n",
      "28    6635       3394  3241        1\n",
      "29   38658      39854  1196        1\n",
      "30    7605       4862  2743        1\n",
      "31   22241      24503  2262        1\n",
      "32   46127      45383   744        0\n",
      "***** end of evaluation using unseen testing data *****\n"
     ]
    }
   ],
   "source": [
    "# create model, use the flag use_polynomial to easily test result between Linear and Polynomial model\n",
    "model, poly = create_model(df, use_polynomial = False)\n",
    "if model is None:\n",
    "    exit(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72ebf73e-8122-4577-a326-c77b21f9f218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data to predict, shape: (3, 2)\n",
      "[[50  1]\n",
      " [50  5]\n",
      " [50 10]]\n",
      "prediction result:\n",
      "[[16095]\n",
      " [15634]\n",
      " [15058]]\n"
     ]
    }
   ],
   "source": [
    "# prepare new data to predict\n",
    "#data_str = \"[[1,10],[1,30],[1,50]]\"\n",
    "data_str = \"[[50,1],[50,5],[50,10]]\"\n",
    "\n",
    "# convert string to numpy.array\n",
    "js = json.loads(data_str)\n",
    "data_to_predict = np.array(js)\n",
    "print(f\"data to predict, shape: {data_to_predict.shape}\")\n",
    "print(data_to_predict)\n",
    "\n",
    "if poly is not None:\n",
    "    # apply the same transformation to the data to be predicted, to ensure the data is in the same form as learned data ('model')\n",
    "    data_to_predict = poly.transform(data_to_predict)\n",
    "\n",
    "# predict\n",
    "result = model.predict(data_to_predict)\n",
    "\n",
    "print(f\"prediction result:\")\n",
    "\n",
    "# attempt to display number without 'e+' notation\n",
    "np.set_printoptions(formatter={'float': '{:0.0f}'.format})\n",
    "\n",
    "print(result)\n",
    "######## end of demo ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad324f-7e08-4f98-8e99-75bf2bf26890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
